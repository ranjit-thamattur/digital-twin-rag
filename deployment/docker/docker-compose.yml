services:   
  openwebui:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: openwebui
    ports:
      - "3000:8080"
    environment:
      ENABLE_PIPELINE_MODE: "true"
      WEBUI_NAME: "Peak AI 1.0"
      DISABLE_OLLAMA: "false"
      OLLAMA_BASE_URL: "http://ollama:11434"
      WEBUI_AUTH: "true"
      OLLAMA_REQUEST_TIMEOUT: "300"
      GLOBAL_LOG_LEVEL: DEBUG
      BYPASS_MODEL_ACCESS_CONTROL: "true"
      WEBUI_URL: ${WEBUI_URL:-http://localhost:3000}
      WEBUI_FAVICON_URL: "/static/favicon.png"
      WEBUI_LOGO_URL: "/static/logo.png"
      # Cognito OIDC Authentication (Matches CloneMindStack)
      ENABLE_OAUTH_SIGNUP: "true"
      OAUTH_PROVIDER_NAME: "Cognito"
      OAUTH_CLIENT_ID: ${COGNITO_CLIENT_ID}
      OAUTH_CLIENT_SECRET: ${COGNITO_CLIENT_SECRET}
      OPENID_PROVIDER_URL: ${COGNITO_OPENID_URL}
      OAUTH_SCOPES: "openid profile email"
      OAUTH_MERGE_ACCOUNTS_BY_EMAIL: "true"
      ENABLE_SIGNUP: "true"
      DEFAULT_USER_ROLE: "user"
    volumes:
      - openwebui_dt_data:/app/backend/data
      - ./pipelines:/app/backend/pipelines
      - ./peak-logo.jpg:/app/backend/static/favicon.png
      - ./peak-logo.jpg:/app/backend/static/logo.png
      - ./peak-logo.jpg:/app/build/favicon.png
      - ./peak-logo.jpg:/app/build/logo.png
      - ./peak-logo.jpg:/app/build/favicon.ico
    networks:
      - ai_net
    depends_on:
      - mcp-server
      - ollama

  mcp-server:
    build:
      context: ../../services/mcp-server
      dockerfile: Dockerfile
    container_name: mcp-server-dt
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6334
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
      - MCP_TRANSPORT=sse
      - TENANT_TABLE=${TENANT_TABLE:-TenantMetadata}
    networks:
      - ai_net
    depends_on:
      - qdrant

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      OLLAMA_KEEP_ALIVE: "30m"
      OLLAMA_MAX_LOADED_MODELS: "3"
      OLLAMA_NUM_PARALLEL: "4"
      OLLAMA_HOST: "0.0.0.0:11434"
      OLLAMA_FLASH_ATTENTION: "1"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - qdrant_dt_data:/qdrant/storage
    networks:
      - ai_net

  localstack:
    image: localstack/localstack:3.0
    container_name: localstack
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,lambda,events,logs,dynamodb,iam,sts
      - DEBUG=1
      - PERSISTENCE=1
      - DATA_DIR=/var/lib/localstack
      - LAMBDA_EXECUTOR=local
      - HOSTNAME_EXTERNAL=localstack
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
    volumes:
      - ./localstack_data:/var/lib/localstack
      - ./lambda:/opt/code/localstack/lambda
    networks:
      - ai_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: redis-dt
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_dt_data:/data
    networks:
      - ai_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  file-sync:
    build:
      context: ../../services/file-sync
      dockerfile: Dockerfile
    container_name: file-sync-dt
    environment:
      S3_ENDPOINT: http://localstack:4566
      S3_BUCKET: ${S3_BUCKET:-digital-twin-docs}
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION:-us-east-1}
    volumes:
      - openwebui_dt_data:/app/backend/data
    networks:
      - ai_net
    depends_on:
      - localstack
      - openwebui
    restart: unless-stopped

  tenant-service:
    build: ../../services/tenant-service
    container_name: tenant-service-dt
    ports:
      - "8000:8000"
    environment:
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION:-us-east-1}
      COGNITO_USER_POOL_ID: ${COGNITO_USER_POOL_ID}
      COGNITO_CLIENT_ID: ${COGNITO_CLIENT_ID}
      TENANT_TABLE: ${TENANT_TABLE:-TenantMetadata}
      # For local dev pointing to LocalStack if needed:
      # AWS_ENDPOINT_URL: http://localstack:4566
    volumes:
      - ../../services/tenant-service:/app
    networks:
      - ai_net
    depends_on:
      - localstack
    restart: unless-stopped

volumes:
  ollama_data:
  openwebui_dt_data:
  qdrant_dt_data:
  redis_dt_data:

networks:
  ai_net:
    driver: bridge

